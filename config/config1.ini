[Train]
#Number of one-step-transition in the buffer, None= one game
InitialBufferSize = 50000
#Number of Q function calculate
Episode = 150
#Number of action in each episode
Episode_Size = 1000
#DecreasingRate of a greedy policy
DecreaseRate = 0.00001
#number of action needed before a update of the target
TargetUpdate = 10000


[Agent]
#Agent
;Agent = FittedQIteration
;Agent = DQNAgent
Agent = DDQNAgent

#Estimator
;Estimator = Linear
;Estimator = RandomTree
Estimator = NeuralNetwork

#Buffer Strategy
;Buffer = Ordered
;Buffer = Random
Buffer = Prioritized

#Maximizer
Maximizer = Static
;Maximizer = Uniform
;Maximizer = BalancedUniform

[Static]
#Numpber of Sample
NumberOfSample = 11

[Uniform]
#Numpber of Sample
NumberOfSample = 11

[BalancedUniform]
#Numpber of sample each side of zero
NumberOfSample = 5